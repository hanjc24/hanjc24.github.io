<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="browsermode" content="application">
<meta name="apple-touch-fullscreen" content="yes">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-title" content="Jicheng's Blog">
<meta name="apple-mobile-web-app-status-bar-style" content="default">
<meta name="msapplication-navbutton-color" content="#666666">
<meta name= "format-detection" content="telephone=no" />

  <link rel="apple-touch-icon"  sizes="72x72"  href="/favicon.png">
  <link rel="apple-touch-icon-precomposed"  sizes="72x72"  href="/favicon.png">



  <meta name="description" content="Here is BD1AEH">



  <meta name="keywords" content="Literature Review, nlvi" />


<link rel="apple-touch-startup-image" media="(device-width: 375px)" href="assets/apple-launch-1125x2436.png">
<link rel="apple-touch-startup-image" media="(orientation: landscape)" href="assets/apple-touch-startup-image-2048x1496.png">

<link rel="stylesheet" href="/style/style.css">

<script>
  var nlviconfig = {
    title: "Jicheng's Blog",
    author: "hanjc24",
    baseUrl: "/",
    theme: {
      scheme: "banderole",
      lightbox: true,
      animate: true,
      search: true,
      friends: false,
      reward: false,
      pjax: false,
      lazy: false,
      toc: true
    }
  }
</script>




    
<link rel="stylesheet" href="/script/lib/lightbox/css/lightbox.min.css">





    
<link rel="stylesheet" href="/syuanpi/syuanpi.min.css">





    <link rel="icon" href="/favicon.png">












<style>
@font-face {
  font-family: "Allura";
  src: url('/font/allura/allura.ttf');
}
</style>

  <title> FlashAttention · Jicheng's Blog </title>
<meta name="generator" content="Hexo 8.1.1"></head>
<body>
  <div class="container">
    <header class="header" id="header">
  <div class="header-wrapper">
    <div class="logo">
  <div class="logo-inner syuanpi tvIn" style="display:none;">
    <h1><a href="/">Jicheng's Blog</a></h1>
    
  </div>
</div>

    <nav class="main-nav">
  
  <ul class="main-nav-list syuanpi tvIn">
  
    <li class="menu-item">
      <a href="javascript:;" id="search-btn" aria-label="Search">
        <i class="iconfont icon-search"></i>
      </a>
    </li>
  
  
  
    
  
    <li class="menu-item">
      <a href="/" id="article">
        <span class="base-name">
          
            ARTICLE
          
        </span>
      </a>
    </li>
  
  
    
  
    <li class="menu-item">
      <a href="/archives" id="archives">
        <span class="base-name">
          
            ARCHIVES
          
        </span>
      </a>
    </li>
  
  
    
  
    <li class="menu-item">
      <a href="javascript:;" id="tags">
        <span class="base-name">
          
            TAGS
          
        </span>
      </a>
    </li>
  
  
    
  
    <li class="menu-item">
      <a href="/about" id="about">
        <span class="base-name">
          
            ABOUT
          
        </span>
      </a>
    </li>
  
  
  </ul>
  
</nav>

  </div>
</header>
<div class="mobile-header" id="mobile-header">
  <div class="mobile-header-nav">
    <div class="mobile-header-item" id="mobile-left">
      <div class="header-menu-item">
        <div class="header-menu-line"></div>
      </div>
    </div>
    <h1 class="mobile-header-title">
      <a href="/">Jicheng's Blog</a>
    </h1>
    <div class="mobile-header-item"></div>
  </div>
  <div class="mobile-header-body">
    <ul class="mobile-header-list">
      
        <li class="mobile-nav-item syuanpi fadeInRightShort back-0">
          <a href="/" >
            
              ARTICLE
            
          </a>
        </li>
      
        <li class="mobile-nav-item syuanpi fadeInRightShort back-1">
          <a href="/archives" >
            
              ARCHIVES
            
          </a>
        </li>
      
        <li class="mobile-nav-item syuanpi fadeInRightShort back-2">
          <a href="javascript:;" id="mobile-tags">
            
              TAGS
            
          </a>
        </li>
      
        <li class="mobile-nav-item syuanpi fadeInRightShort back-3">
          <a href="/about" >
            
              ABOUT
            
          </a>
        </li>
      
    </ul>
  </div>
</div>



    <div class="container-inner" style="display:none;">
      <main class="main" id="main">
        <div class="main-wrapper">
          
    
  
  <article class="
  post
   is_post 
  ">
    <header class="post-header">
      <div class="post-time syuanpi fadeInRightShort back-1">
        <div class="post-time-wrapper">
          
          <time>2026-01-17</time>
          
            
              <span class="post-category"><a href="/categories/Academic/">Academic</a></span>
            
          
        </div>
      </div>
      <h1 class="post-title syuanpi fadeInRightShort back-2">
        
          FlashAttention
        
      </h1>
    </header>
    <div class="post-content syuanpi fadeInRightShort back-3">
      
        <p>FlashAttention的目的很简单：<br>
如何高效计算<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo>=</mo><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O=Attention(Q,K,V)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span></span></span></span></p>
<h3 id="FlashAttention-1实现">FlashAttention-1实现</h3>
<img src="/2026/01/17/FlashAttention/image.png" class="" title="This is an example image">
<ul>
<li><strong>分块计算<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>但不存储它</strong><br>
从上方图可以看出，原始的FA设计是outer loop为KV blocks，inner loop为Q<br>
可以在不同batch与不同head上并行，单个batch上单个head的双重循环是串行的</li>
<li><strong>O的合并更新</strong><br>
第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>行：维护<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>s</mi><msub><mi>e</mi><mi>i</mi></msub><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><msub><mo>∑</mo><mi>j</mi></msub><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi>T</mi></msubsup><msub><mo stretchy="false">)</mo><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">lse_i=log\sum_j exp((Q_iK_j^T)_{ij})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">s</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2771em;vertical-align:-0.4358em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">((</span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.4413em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>m</mi><mi>i</mi></msub><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi>T</mi></msubsup><msub><mo stretchy="false">)</mo><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">m_i=max((Q_iK_j^T)_{ij})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2361em;vertical-align:-0.3948em;"></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">((</span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.4413em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>o</mi><mi>i</mi></msub><mo>=</mo><msub><mo>∑</mo><mi>j</mi></msub><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><msub><mo stretchy="false">)</mo><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>m</mi><mi>i</mi></msub><mo stretchy="false">)</mo><msub><mi>V</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">o_i=\sum_j exp((QK^T)_{ij}-m_i)V_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2771em;vertical-align:-0.4358em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">((</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span><br>
这样可以实现在线更新<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>o</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">o_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，具体实现见代码</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.14135">FA arxiv link</a><br>
<a target="_blank" rel="noopener" href="https://github.com/Dao-AILab/flash-attention">github link</a></p>
<h3 id="NSA的GQA版本FA的实现">NSA的GQA版本FA的实现</h3>
<h4 id="修改双重循环">修改双重循环</h4>
<p>DeepSeekNSA中的Triton实现的FlashAttention Forward Kernel<br>
外层循环q block(其实是并行的)，内层循环kv block(在线程块内串行)<br>
FlashAttenion-2中其实也做了一样的修改，这样q block也可以并行，而如果按照原来的做法，q block是无法并行的，因为会涉及到o的更新的数据同步问题</p>
<h4 id="代码分析">代码分析</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_kernel</span>(<span class="params"></span></span><br><span class="line"><span class="params">    q_ptr,  <span class="comment"># Q: n x NUM_Q_HEADS(h) x qk_head_dim(d) 这里n都是整个序列长(所有batch拼成的)</span></span></span><br><span class="line"><span class="params">    k_ptr,  <span class="comment"># K: n x NUM_KV_HEADS(h) x qk_head_dim(d)</span></span></span><br><span class="line"><span class="params">    v_ptr,  <span class="comment"># V: n x NUM_KV_HEADS(h) x v_head_dim(d)</span></span></span><br><span class="line"><span class="params">    o_ptr,  <span class="comment"># O: n x NUM_Q_HEADS(h) x v_head_dim(d)</span></span></span><br><span class="line"><span class="params">    lse_ptr,  <span class="comment"># LSE: NUM_Q_HEADS(h) x n   (log-sum-exp)</span></span></span><br><span class="line"><span class="params">    <span class="comment"># seqlens</span></span></span><br><span class="line"><span class="params">    cu_seqlens_q, <span class="comment"># 累积序列长度，用于处理可变长度序列，描述长度为n的完整序列中每个batch的范围</span></span></span><br><span class="line"><span class="params">    <span class="comment"># 存储：[0, seq_len1, seq_len1+seq_len2, ...] [0,seq_len1)为batch0，[seq_len1,seq_len2)为batch1，...</span></span></span><br><span class="line"><span class="params">    cu_seqlens_k, <span class="comment"># 用于处理cross-attention的情况，但在self attention中与cu_seqlens_q应当一致</span></span></span><br><span class="line"><span class="params">    <span class="comment"># shape</span></span></span><br><span class="line"><span class="params">    NUM_KV_HEADS, <span class="comment"># Key/Value的头数</span></span></span><br><span class="line"><span class="params">    NUM_SHARE_Q_HEADS, <span class="comment"># 共享一个Key/Value头的Query头数，即一个查询组中的查询头数G</span></span></span><br><span class="line"><span class="params">    qk_head_dim, <span class="comment"># query与key向量的维数 d</span></span></span><br><span class="line"><span class="params">    v_head_dim,  <span class="comment"># value与output向量的维数 d 二者一般一样</span></span></span><br><span class="line"><span class="params">    <span class="comment"># sm_scale</span></span></span><br><span class="line"><span class="params">    sm_scale, <span class="comment"># softmax计算前的缩放因子，保证注意力分数分布的标准差大致为1，取1/sqrt(qk_head_dim)</span></span></span><br><span class="line"><span class="params">    <span class="comment"># causal</span></span></span><br><span class="line"><span class="params">    causal, <span class="comment"># 是否使用因果掩码</span></span></span><br><span class="line"><span class="params">    <span class="comment"># gqa</span></span></span><br><span class="line"><span class="params">    gqa_interleave,</span></span><br><span class="line"><span class="params">    <span class="comment"># stride 四个矩阵的物理stride</span></span></span><br><span class="line"><span class="params">    stride_qn,</span></span><br><span class="line"><span class="params">    stride_qh,</span></span><br><span class="line"><span class="params">    stride_qd,</span></span><br><span class="line"><span class="params">    stride_kn,</span></span><br><span class="line"><span class="params">    stride_kh,</span></span><br><span class="line"><span class="params">    stride_kd,</span></span><br><span class="line"><span class="params">    stride_vn,</span></span><br><span class="line"><span class="params">    stride_vh,</span></span><br><span class="line"><span class="params">    stride_vd,</span></span><br><span class="line"><span class="params">    stride_on,</span></span><br><span class="line"><span class="params">    stride_oh,</span></span><br><span class="line"><span class="params">    stride_od,</span></span><br><span class="line"><span class="params">    stride_lh,</span></span><br><span class="line"><span class="params">    stride_ln,</span></span><br><span class="line"><span class="params">    <span class="comment"># META parameters</span></span></span><br><span class="line"><span class="params">    BLOCK_SIZE_Q: tl.constexpr,  <span class="comment"># q block size </span></span></span><br><span class="line"><span class="params">    BLOCK_SIZE_K: tl.constexpr,  <span class="comment"># k block size FlashAttention内层循环的步长/块大小</span></span></span><br><span class="line"><span class="params">    BLOCK_SIZE_KD: tl.constexpr, <span class="comment"># 大于等于qk_head_dim的2的幂，用于加载</span></span></span><br><span class="line"><span class="params">    BLOCK_SIZE_VD: tl.constexpr, <span class="comment"># 大于等于v_head_dim的2的幂，用于加载</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    qk_scale = sm_scale * <span class="number">1.44269504</span> <span class="comment"># 输入的sm_scale是按照softmax使用e^x计算，但实际使用的函数是2^x，这里是乘以1/ln2来补偿</span></span><br><span class="line">    <span class="comment"># get batch id and head id</span></span><br><span class="line">    pid_b = tl.program_id(<span class="number">0</span>) <span class="comment"># 批次（batch）的索引(多个batch序列被拼成一个很长的token序列)</span></span><br><span class="line">    pid_h = tl.program_id(<span class="number">1</span>) <span class="comment"># query头（head）的索引</span></span><br><span class="line">    pid_q = tl.program_id(<span class="number">2</span>) <span class="comment"># 这一query头的在其所在的batch序列内的块索引</span></span><br><span class="line">    <span class="keyword">if</span> gqa_interleave:</span><br><span class="line">        pid_kh = pid_h % NUM_KV_HEADS <span class="comment"># kv头的索引 GQA中同查询组query头共用kv头</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pid_kh = pid_h // NUM_SHARE_Q_HEADS</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># get q k start and len after rmpad 根据pid_b确定batch序列的范围，该线程块只处理这个batch中的一个BLOCK_SIZE_Q大小的块</span></span><br><span class="line">    q_start = tl.load(cu_seqlens_q + pid_b)</span><br><span class="line">    q_len = tl.load(cu_seqlens_q + pid_b + <span class="number">1</span>) - q_start <span class="comment"># 这个batch处理的是[q_start,q_start+q_len)的输入序列</span></span><br><span class="line">    k_start = tl.load(cu_seqlens_k + pid_b)</span><br><span class="line">    k_len = tl.load(cu_seqlens_k + pid_b + <span class="number">1</span>) - k_start</span><br><span class="line">    <span class="keyword">if</span> BLOCK_SIZE_Q * pid_q &gt;= q_len: </span><br><span class="line">        <span class="comment"># 如果当前q_block块索引范围[BLOCK_SIZE_Q * pid_q, BLOCK_SIZE_Q * (pid_q+1))完全超过了当前batch范围，直接返回</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># init qkv pointer</span></span><br><span class="line">    q_ptrs = tl.make_block_ptr(</span><br><span class="line">        base=q_ptr + q_start * stride_qn + pid_h * stride_qh,</span><br><span class="line">        shape=(q_len, qk_head_dim),</span><br><span class="line">        strides=(stride_qn, stride_qd),</span><br><span class="line">        offsets=(pid_q * BLOCK_SIZE_Q, <span class="number">0</span>),</span><br><span class="line">        block_shape=(BLOCK_SIZE_Q, BLOCK_SIZE_KD),</span><br><span class="line">        order=(<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    )</span><br><span class="line">    k_ptrs = tl.make_block_ptr(</span><br><span class="line">        base=k_ptr + k_start * stride_kn + pid_kh * stride_kh,</span><br><span class="line">        shape=(qk_head_dim, k_len),</span><br><span class="line">        strides=(stride_kd, stride_kn),</span><br><span class="line">        offsets=(<span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">        block_shape=(BLOCK_SIZE_KD, BLOCK_SIZE_K),</span><br><span class="line">        order=(<span class="number">0</span>, <span class="number">1</span>), <span class="comment"># 这里的block ptr在初始化的时候就是转置的</span></span><br><span class="line">    )</span><br><span class="line">    v_ptrs = tl.make_block_ptr(</span><br><span class="line">        base=v_ptr + k_start * stride_vn + pid_kh * stride_vh,</span><br><span class="line">        shape=(k_len, v_head_dim),</span><br><span class="line">        strides=(stride_vn, stride_vd),</span><br><span class="line">        offsets=(<span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">        block_shape=(BLOCK_SIZE_K, BLOCK_SIZE_VD),</span><br><span class="line">        order=(<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># load q 本线程块只需加载一次即可</span></span><br><span class="line">    q = tl.load(q_ptrs, boundary_check=(<span class="number">0</span>, <span class="number">1</span>), padding_option=<span class="string">&quot;zero&quot;</span>)</span><br><span class="line">    <span class="comment"># init statistics</span></span><br><span class="line">    off_q = tl.arange(<span class="number">0</span>, BLOCK_SIZE_Q) + pid_q * BLOCK_SIZE_Q</span><br><span class="line">    off_k = tl.arange(<span class="number">0</span>, BLOCK_SIZE_K)</span><br><span class="line">    m_i = tl.full((BLOCK_SIZE_Q,), <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>), dtype=tl.float32) <span class="comment"># 各行最大的e^qk</span></span><br><span class="line">    lse_i = tl.full((BLOCK_SIZE_Q,), <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>), dtype=tl.float32) <span class="comment"># 各行qk的lse logΣe^qk</span></span><br><span class="line">    acc_o = tl.full((BLOCK_SIZE_Q, BLOCK_SIZE_VD), <span class="number">0</span>, dtype=tl.float32) <span class="comment"># 最终结果O 在循环过程中存放的qk*v再除以exp2(m_i)的中间结果</span></span><br><span class="line">    <span class="comment"># full attention or causal attention</span></span><br><span class="line">    lo = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> causal:</span><br><span class="line">        hi = <span class="built_in">min</span>(k_len, (pid_q + <span class="number">1</span>) * BLOCK_SIZE_Q)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        hi = k_len</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lo, hi, BLOCK_SIZE_K):</span><br><span class="line">        i = tl.multiple_of(i, BLOCK_SIZE_K)</span><br><span class="line">        <span class="comment"># load k^T</span></span><br><span class="line">        k = tl.load(k_ptrs, boundary_check=(<span class="number">1</span>, <span class="number">0</span>), padding_option=<span class="string">&quot;zero&quot;</span>)</span><br><span class="line">        <span class="comment"># compute qk^T</span></span><br><span class="line">        qk = tl.zeros((BLOCK_SIZE_Q, BLOCK_SIZE_K), dtype=tl.float32)</span><br><span class="line">        <span class="keyword">if</span> causal:</span><br><span class="line">            qk += tl.where(off_q[:, <span class="literal">None</span>] &gt;= (i + off_k)[<span class="literal">None</span>, :], <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            qk += tl.where((off_k &lt; k_len - i)[<span class="literal">None</span>, :], <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>))</span><br><span class="line">        qk += tl.dot(q, k) * qk_scale</span><br><span class="line">        <span class="comment"># compute m_ij and l_ij</span></span><br><span class="line">        m_ij = tl.maximum(m_i, tl.<span class="built_in">max</span>(qk, axis=<span class="number">1</span>)) <span class="comment"># 大小：BLOCK_SIZE_Q，每行求最大值</span></span><br><span class="line">        p = tl.math.exp2(qk - m_ij[:, <span class="literal">None</span>]) <span class="comment"># 本块放缩后的注意力分数，BLOCK_SIZE_Q * BLOCK_SIZE_K</span></span><br><span class="line">        l_ij = tl.<span class="built_in">sum</span>(p, axis=<span class="number">1</span>) <span class="comment"># 本块放缩后的注意力分数和se，BLOCK_SIZE_Q</span></span><br><span class="line">        <span class="comment"># scale acc_o</span></span><br><span class="line">        acc_o_scale = tl.math.exp2(m_i - m_ij)</span><br><span class="line">        acc_o = acc_o * acc_o_scale[:, <span class="literal">None</span>] <span class="comment"># 将放缩量更新为exp2(m_ij)</span></span><br><span class="line">        <span class="comment"># load v and update acc_o</span></span><br><span class="line">        v = tl.load(v_ptrs, boundary_check=(<span class="number">0</span>, <span class="number">1</span>), padding_option=<span class="string">&quot;zero&quot;</span>) <span class="comment"># BLOCK_K * v_head_dim</span></span><br><span class="line">        p = p.to(v.dtype)</span><br><span class="line">        acc_o += tl.dot(p, v)</span><br><span class="line">        <span class="comment"># update statistics</span></span><br><span class="line">        m_i = m_ij</span><br><span class="line">        lse_i = m_ij + tl.math.log2(tl.math.exp2(lse_i - m_ij) + l_ij)</span><br><span class="line">        <span class="comment"># update ptrs</span></span><br><span class="line">        k_ptrs = tl.advance(k_ptrs, (<span class="number">0</span>, BLOCK_SIZE_K)) <span class="comment"># FlashAttention内层循环移动</span></span><br><span class="line">        v_ptrs = tl.advance(v_ptrs, (BLOCK_SIZE_K, <span class="number">0</span>))</span><br><span class="line">    <span class="comment"># final scale</span></span><br><span class="line">    acc_o = acc_o * tl.math.exp2(m_i - lse_i)[:, <span class="literal">None</span>]</span><br><span class="line">    <span class="comment"># save output</span></span><br><span class="line">    o_ptrs = tl.make_block_ptr(</span><br><span class="line">        base=o_ptr + q_start * stride_on + pid_h * stride_oh,</span><br><span class="line">        shape=(q_len, v_head_dim),</span><br><span class="line">        strides=(stride_on, stride_od),</span><br><span class="line">        offsets=(pid_q * BLOCK_SIZE_Q, <span class="number">0</span>),</span><br><span class="line">        block_shape=(BLOCK_SIZE_Q, BLOCK_SIZE_VD),</span><br><span class="line">        order=(<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    )</span><br><span class="line">    tl.store(o_ptrs, acc_o.to(o_ptr.dtype.element_ty), boundary_check=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># save lse</span></span><br><span class="line">    l_ptrs = lse_ptr + q_start * stride_ln + pid_h * stride_lh + off_q * stride_ln</span><br><span class="line">    tl.store(l_ptrs, lse_i, mask=off_q &lt; q_len)</span><br></pre></td></tr></table></figure>
      
    
    </div>
    
      <div class="post-tags syuanpi fadeInRightShort back-3">
      
        <a href="/tags/Literature-Review/">Literature Review</a>
      
      </div>
    
    
      

      
  <hr class="copy-line">
  <div class="post-copyright">
    <div class="copy-author">
      <span>Author :</span>
      <span>hanjc24</span>
    </div>
    <div class="copy-url">
      <span>Url :</span>
      <a href="http://hanjc24.github.io/2026/01/17/FlashAttention/">http://hanjc24.github.io/2026/01/17/FlashAttention/</a>
    </div>
    <div class="copy-origin">
      <span>Origin :</span>
      <a href="http://hanjc24.github.io">http://hanjc24.github.io</a>
    </div>
    <div class="copy-license">
      
      All rights reserved. Please contact the author for authorization to reprint.
    </div>
  </div>

    
  </article>
  
    
  <nav class="article-page">
    
      <a href="/2026/01/17/HexoNlviBuild/" id="art-left" class="art-left">
        <span class="next-title">
          <i class="iconfont icon-left"></i>How to customize Hexo theme Nlvi
        </span>
      </a>
    
    
      <a href="/2026/01/16/hello-world/" id="art-right" class="art-right">
        <span class="prev-title">
          CQ CQ This is BD1AEH. Standing by.<i class="iconfont icon-right"></i>
        </span>
      </a>
    
  </nav>


    
  <i id="com-switch" class="iconfont icon-down jumping-in long infinite" style="font-size:24px;display:block;text-align:center;transform:rotate(180deg);"></i>
  <div class="post-comments" id="post-comments" style="display: block;margin: auto 16px;">
    

    
    

    

    

  </div>



  
  
    
  
  <aside class="post-toc">
    <div class="title"><span>Index</span></div>
    <div class="toc-inner">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#FlashAttention-1%E5%AE%9E%E7%8E%B0"><span class="toc-text">FlashAttention-1实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NSA%E7%9A%84GQA%E7%89%88%E6%9C%ACFA%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-text">NSA的GQA版本FA的实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E5%8F%8C%E9%87%8D%E5%BE%AA%E7%8E%AF"><span class="toc-text">修改双重循环</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90"><span class="toc-text">代码分析</span></a></li></ol></li></ol>
    </div>
  </aside>



  


        </div>
      </main>
      <footer class="footer syuanpi fadeIn" id="footer">
  <hr>
  <div class="footer-wrapper">
    <div class="left">
      <div class="contact-icon">
  
  
    <a target="_blank" rel="noopener" href="https://github.com/hanjc24" class="iconfont icon-github" title="github"></a>
  
</div>

    </div>
    <div class="right">
      <div class="copyright">
    <div class="info">
        <span>&copy;</span>
        <span>2026 ~ 2026</span>
        <span>❤</span>
        <span>hanjc24</span>
    </div>
    <div class="theme">
        <span>
            Powered by
            <a href="http://hexo.io/" target="_blank" rel="noopener">Hexo </a>
        </span>
        <span>
            Theme
            <a target="_blank" rel="noopener" href="https://github.com/ColMugX/hexo-theme-Nlvi"> Nlvi </a>
        </span>
    </div>
    
</div>

    </div>
  </div>
</footer>
    </div>
    <div class="tagcloud" id="tagcloud">
  <div class="tagcloud-taglist">
  
    <div class="tagcloud-tag">
      <button>Daily Log</button>
    </div>
  
    <div class="tagcloud-tag">
      <button>Literature Review</button>
    </div>
  
    <div class="tagcloud-tag">
      <button>Tutorial</button>
    </div>
  
    <div class="tagcloud-tag">
      <button>Project</button>
    </div>
  
    <div class="tagcloud-tag">
      <button>李宏毅ML</button>
    </div>
  
    <div class="tagcloud-tag">
      <button>CS231n</button>
    </div>
  
  </div>
  
    <div class="tagcloud-postlist active">
      <h2>Daily Log</h2>
      
        <div class="tagcloud-post">
          <a href="/2026/01/16/hello-world/">
            <time class="tagcloud-posttime">2026 / 01 / 16</time>
            <span>CQ CQ This is BD1AEH. Standing by.</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/19/CQ-CQ-CQ-This-is-BD1AEH-calling/">
            <time class="tagcloud-posttime">2026 / 01 / 19</time>
            <span>CQ CQ CQ This is BD1AEH calling</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/20/EETalk-Project/">
            <time class="tagcloud-posttime">2026 / 01 / 20</time>
            <span>EETalk Project</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/THUCS培养体系/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>THU-CS培养方案</span>
          </a>
        </div>
      
    </div>
  
    <div class="tagcloud-postlist ">
      <h2>Literature Review</h2>
      
        <div class="tagcloud-post">
          <a href="/2026/01/17/FlashAttention/">
            <time class="tagcloud-posttime">2026 / 01 / 17</time>
            <span>FlashAttention</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/18/infllmv2-paper-review/">
            <time class="tagcloud-posttime">2026 / 01 / 18</time>
            <span>Infllmv2 Review</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/19/DeepSeekNSA/">
            <time class="tagcloud-posttime">2026 / 01 / 19</time>
            <span>DeepSeekNSA</span>
          </a>
        </div>
      
    </div>
  
    <div class="tagcloud-postlist ">
      <h2>Tutorial</h2>
      
        <div class="tagcloud-post">
          <a href="/2026/01/17/HexoNlviBuild/">
            <time class="tagcloud-posttime">2026 / 01 / 17</time>
            <span>How to customize Hexo theme Nlvi</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/18/How-to-use-Mermaid-in-Hexo/">
            <time class="tagcloud-posttime">2026 / 01 / 18</time>
            <span>How to use Mermaid in Hexo</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/22/Learning-Triton/">
            <time class="tagcloud-posttime">2026 / 01 / 22</time>
            <span>Learning Triton</span>
          </a>
        </div>
      
    </div>
  
    <div class="tagcloud-postlist ">
      <h2>Project</h2>
      
        <div class="tagcloud-post">
          <a href="/2026/01/20/EETalk-Project/">
            <time class="tagcloud-posttime">2026 / 01 / 20</time>
            <span>EETalk Project</span>
          </a>
        </div>
      
    </div>
  
    <div class="tagcloud-postlist ">
      <h2>李宏毅ML</h2>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L2TrainIssue/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L2 Train Issue</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L1Regression/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L1 Regression</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L3Classification/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L3 Classification</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L4CNN/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L4 CNN</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L5SelfAttention/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L5 Self-Attention</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L6Transformer/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L6 Transformer</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L8self-supervised/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L8 Self-supervised Learning</span>
          </a>
        </div>
      
    </div>
  
    <div class="tagcloud-postlist ">
      <h2>CS231n</h2>
      
        <div class="tagcloud-post">
          <a href="/2026/01/25/Backpropagation/">
            <time class="tagcloud-posttime">2026 / 01 / 25</time>
            <span>Backpropagation</span>
          </a>
        </div>
      
    </div>
  
</div>

  </div>
  <div class="backtop syuanpi melt toTop" id="backtop">
    <i class="iconfont icon-up"></i>
    <span style="text-align:center;font-family:Georgia;"><span style="font-family:Georgia;" id="scrollpercent">1</span>%</span>
</div>

  <div class="search" id="search">
    <div class="input">
      <input type="text" id="search-input" placeholder="搜索一下？" autofocus>
    </div>
    <div id="search-result"></div>
  </div>



<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>








  <script></script>
  <script src="/script/lib/lightbox/js/lightbox.min.js" async></script>











  
<script src="/script/scheme/banderole.js"></script>




<script src="/script/bootstarp.js"></script>



<script>
if (nlviconfig.theme.toc) {
  setTimeout(function() {
    if (nlviconfig.theme.scheme === 'balance') {
      $("#header").addClass("show_toc");
    } else if (nlviconfig.theme.scheme === 'banderole') {
      $(".container-inner").addClass("has_toc");
      $(".post-toc .title").addClass("show");
      $(".toc-inner").addClass("show");
    }
  }, 1000);
}
</script>



  
<script src="/script/lib/mermaid/mermaid.min.js"></script>

  <script>
    $(document).ready(function() {
      var mermaid_config = {
        startOnLoad: true,
        theme: '',
        flowchart: {
          useMaxWidth: false,
          htmlLabels: true
        }
      };
      mermaid.initialize(mermaid_config);
    });
  </script>


<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"
/>


</body>
</html>
