<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="browsermode" content="application">
<meta name="apple-touch-fullscreen" content="yes">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-title" content="Jicheng's Blog">
<meta name="apple-mobile-web-app-status-bar-style" content="default">
<meta name="msapplication-navbutton-color" content="#666666">
<meta name= "format-detection" content="telephone=no" />

  <link rel="apple-touch-icon"  sizes="72x72"  href="/favicon.png">
  <link rel="apple-touch-icon-precomposed"  sizes="72x72"  href="/favicon.png">



  <meta name="description" content="Here is BD1AEH">




<link rel="apple-touch-startup-image" media="(device-width: 375px)" href="assets/apple-launch-1125x2436.png">
<link rel="apple-touch-startup-image" media="(orientation: landscape)" href="assets/apple-touch-startup-image-2048x1496.png">

<link rel="stylesheet" href="/style/style.css">

<script>
  var nlviconfig = {
    title: "Jicheng's Blog",
    author: "hanjc24",
    baseUrl: "/",
    theme: {
      scheme: "banderole",
      lightbox: true,
      animate: true,
      search: true,
      friends: false,
      reward: false,
      pjax: false,
      lazy: false,
      toc: true
    }
  }
</script>




    
<link rel="stylesheet" href="/script/lib/lightbox/css/lightbox.min.css">





    
<link rel="stylesheet" href="/syuanpi/syuanpi.min.css">





    <link rel="icon" href="/favicon.png">












<style>
@font-face {
  font-family: "Allura";
  src: url('/font/allura/allura.ttf');
}
</style>

  <title>
  Jicheng's Blog
  
</title>
<meta name="generator" content="Hexo 8.1.1"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>
<body>
  <div class="container">
    <header class="header" id="header">
  <div class="header-wrapper">
    <div class="logo">
  <div class="logo-inner syuanpi tvIn" style="display:none;">
    <h1><a href="/">Jicheng's Blog</a></h1>
    
  </div>
</div>

    <nav class="main-nav">
  
  <ul class="main-nav-list syuanpi tvIn">
  
    <li class="menu-item">
      <a href="javascript:;" id="search-btn" aria-label="Search">
        <i class="iconfont icon-search"></i>
      </a>
    </li>
  
  
  
    
  
    <li class="menu-item">
      <a href="/" id="article">
        <span class="base-name">
          
            ARTICLE
          
        </span>
      </a>
    </li>
  
  
    
  
    <li class="menu-item">
      <a href="/archives" id="archives">
        <span class="base-name">
          
            ARCHIVES
          
        </span>
      </a>
    </li>
  
  
    
  
    <li class="menu-item">
      <a href="javascript:;" id="tags">
        <span class="base-name">
          
            TAGS
          
        </span>
      </a>
    </li>
  
  
    
  
    <li class="menu-item">
      <a href="/about" id="about">
        <span class="base-name">
          
            ABOUT
          
        </span>
      </a>
    </li>
  
  
  </ul>
  
</nav>

  </div>
</header>
<div class="mobile-header" id="mobile-header">
  <div class="mobile-header-nav">
    <div class="mobile-header-item" id="mobile-left">
      <div class="header-menu-item">
        <div class="header-menu-line"></div>
      </div>
    </div>
    <h1 class="mobile-header-title">
      <a href="/">Jicheng's Blog</a>
    </h1>
    <div class="mobile-header-item"></div>
  </div>
  <div class="mobile-header-body">
    <ul class="mobile-header-list">
      
        <li class="mobile-nav-item syuanpi fadeInRightShort back-0">
          <a href="/" >
            
              ARTICLE
            
          </a>
        </li>
      
        <li class="mobile-nav-item syuanpi fadeInRightShort back-1">
          <a href="/archives" >
            
              ARCHIVES
            
          </a>
        </li>
      
        <li class="mobile-nav-item syuanpi fadeInRightShort back-2">
          <a href="javascript:;" id="mobile-tags">
            
              TAGS
            
          </a>
        </li>
      
        <li class="mobile-nav-item syuanpi fadeInRightShort back-3">
          <a href="/about" >
            
              ABOUT
            
          </a>
        </li>
      
    </ul>
  </div>
</div>



    <div class="container-inner" style="display:none;">
      <main class="main" id="main">
        <div class="main-wrapper">
          
  

<section class="posts">
  
    
  
  <article class="
  post
  
  ">
    <header class="post-header">
      <div class="post-time syuanpi fadeInRightShort back-1">
        <div class="post-time-wrapper">
          
          <time>2026-01-19</time>
          
            
              <span class="post-category"><a href="/categories/Hobby/">Hobby</a></span>
            
          
        </div>
      </div>
      <h1 class="post-title syuanpi fadeInRightShort back-2">
        
          <a href="/2026/01/19/CQ-CQ-CQ-This-is-BD1AEH-calling/">CQ CQ CQ This is BD1AEH calling</a>
        
      </h1>
    </header>
    <div class="post-content syuanpi fadeInRightShort back-3">
      
        
          <h2 id="MileStone">MileStone</h2>
<p>记录一下我在业余无线电方面的里程碑</p>
<h3 id="收听国际空间站SSTV">收听国际空间站SSTV</h3>
<p>我在半夜从实验室回到宿舍，恰逢国际空间站SSTV广播活动期间，大角度过顶清华大学，欣然拿上设备骑车到紫荆操场进行收听。彼时天朗气清，彩云追月。<br>
在学校无线电社团群发图炫耀，发现收到的图片质量比学校社团用定向天线的效果还要好，甚是喜悦</p>
<ul>
<li>设备：UV-5R+拉杆天线、音频对录线、手机+SSTV encoder软件</li>
</ul>
        
      
    
      <p class="content-link">
        <a href="/2026/01/19/CQ-CQ-CQ-This-is-BD1AEH-calling/">
          <span>Read More...</span>
        </a>
      </p>
    
    </div>
    
      <div class="post-tags syuanpi fadeInRightShort back-3">
      
        <a href="/tags/Daily-Log/">Daily Log</a>
      
      </div>
    
    
  </article>
  
  
    
  

  
    
  
  <article class="
  post
  
  ">
    <header class="post-header">
      <div class="post-time syuanpi fadeInRightShort back-1">
        <div class="post-time-wrapper">
          
          <time>2026-01-19</time>
          
            
              <span class="post-category"><a href="/categories/Academic/">Academic</a></span>
            
          
        </div>
      </div>
      <h1 class="post-title syuanpi fadeInRightShort back-2">
        
          <a href="/2026/01/19/DeepSeekNSA/">DeepSeekNSA</a>
        
      </h1>
    </header>
    <div class="post-content syuanpi fadeInRightShort back-3">
      
        
          <h2 id="要点">要点</h2>
<ul>
<li>三种KV映射方式，一层三次attention计算，<strong>blockwise select与trainable参数</strong>选择模式</li>
<li>计算时使用<strong>GQA+query group共用相同的selected blocks</strong>，保证计算效率充分利用GPU，slc策略的attention计算中，每次加载一个query group同位置<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.817ex" height="1.441ex" role="img" focusable="false" viewBox="0 -626 361 637"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></svg></mjx-container>上的所有<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.774ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 784.3 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g></svg></mjx-container></li>
</ul>
        
      
    
      <p class="content-link">
        <a href="/2026/01/19/DeepSeekNSA/">
          <span>Read More...</span>
        </a>
      </p>
    
    </div>
    
      <div class="post-tags syuanpi fadeInRightShort back-3">
      
        <a href="/tags/Literature-Review/">Literature Review</a>
      
      </div>
    
    
  </article>
  
  
    
  

  
    
  
  <article class="
  post
  
  ">
    <header class="post-header">
      <div class="post-time syuanpi fadeInRightShort back-1">
        <div class="post-time-wrapper">
          
          <time>2026-01-18</time>
          
            
              <span class="post-category"><a href="/categories/Academic/">Academic</a></span>
            
          
        </div>
      </div>
      <h1 class="post-title syuanpi fadeInRightShort back-2">
        
          <a href="/2026/01/18/infllmv2-paper-review/">Infllmv2 Review</a>
        
      </h1>
    </header>
    <div class="post-content syuanpi fadeInRightShort back-3">
      
        
          <h2 id="要点">要点</h2>
<ul>
<li><strong>Shared KV</strong>: 统一整合init(fix window)、top-k(sparse)、local(sliding window)，在选择好要关注的block之后统一进行flashattention运算，共享一套KV projection</li>
<li><strong>Aligned Computation</strong>: 预训练和短文本推理用密集注意力，finetune和长文本推理用稀疏注意力。
<ul>
<li>短文本训练与推理时用密集模式避免额外稀疏计算</li>
<li>长文本finetune时，通过构建尽可能与密集模式相似的稀疏注意力模式，保证模型不会忘掉在短文本训练时学到的知识</li>
<li>两种注意力模式所需要的参数是完全一致的，稀疏注意力没有额外参数。</li>
</ul>
</li>
<li>GQA与稀疏模式查询组内共享保证sparse attention的运算效率</li>
<li>简化的稀疏top-k块选择机制</li>
</ul>
        
      
    
      <p class="content-link">
        <a href="/2026/01/18/infllmv2-paper-review/">
          <span>Read More...</span>
        </a>
      </p>
    
    </div>
    
      <div class="post-tags syuanpi fadeInRightShort back-3">
      
        <a href="/tags/Literature-Review/">Literature Review</a>
      
      </div>
    
    
  </article>
  
  
    
  

  
    
  
  <article class="
  post
  
  ">
    <header class="post-header">
      <div class="post-time syuanpi fadeInRightShort back-1">
        <div class="post-time-wrapper">
          
          <time>2026-01-18</time>
          
            
              <span class="post-category"><a href="/categories/Hexo/">Hexo</a></span>
            
          
        </div>
      </div>
      <h1 class="post-title syuanpi fadeInRightShort back-2">
        
          <a href="/2026/01/18/How-to-use-Mermaid-in-Hexo/">How to use Mermaid in Hexo</a>
        
      </h1>
    </header>
    <div class="post-content syuanpi fadeInRightShort back-3">
      
        
          <p>总之，我在Hexo中用上了Mermaid，在此记录</p>
<pre class="mermaid">graph TD
A[hexo-filter-mermaid-diagrams npm插件] -- 识别md mermaid块 --&gt; C
C[生成class=mermaid的pre块]
B[swig脚本] --模板引擎展开--&gt; D
D[生成引入mermaid库的js代码段]
C--&gt;E
D--&gt;E
E[生成的html中成功渲染mermaid]</pre>
        
      
    
      <p class="content-link">
        <a href="/2026/01/18/How-to-use-Mermaid-in-Hexo/">
          <span>Read More...</span>
        </a>
      </p>
    
    </div>
    
      <div class="post-tags syuanpi fadeInRightShort back-3">
      
        <a href="/tags/Tutorial/">Tutorial</a>
      
      </div>
    
    
  </article>
  
  
    
  

  
    
  
  <article class="
  post
  
  ">
    <header class="post-header">
      <div class="post-time syuanpi fadeInRightShort back-1">
        <div class="post-time-wrapper">
          
          <time>2026-01-17</time>
          
            
              <span class="post-category"><a href="/categories/Hexo/">Hexo</a></span>
            
          
        </div>
      </div>
      <h1 class="post-title syuanpi fadeInRightShort back-2">
        
          <a href="/2026/01/17/HexoNlviBuild/">How to customize Hexo theme Nlvi</a>
        
      </h1>
    </header>
    <div class="post-content syuanpi fadeInRightShort back-3">
      
        
          <h2 id="缘起">缘起</h2>
<p>Nlvi是我的一位学长在<a target="_blank" rel="noopener" href="https://aajax.top/">他的blog</a>魔改并使用的主题，我也装了Nlvi试了试，效果不错，尤其是Tag的索引做得挺清楚的，整体很简约。</p>
<p>唯一的美中不足是原本的Nlvi主题配色的底色都是浅色，观感上过于明亮，所以我研究了一下Hexo theme的结构，修改了一些生成css部分的代码。</p>
        
      
    
      <p class="content-link">
        <a href="/2026/01/17/HexoNlviBuild/">
          <span>Read More...</span>
        </a>
      </p>
    
    </div>
    
      <div class="post-tags syuanpi fadeInRightShort back-3">
      
        <a href="/tags/Tutorial/">Tutorial</a>
      
      </div>
    
    
  </article>
  
  
    
  

  
    
  
  <article class="
  post
  
  ">
    <header class="post-header">
      <div class="post-time syuanpi fadeInRightShort back-1">
        <div class="post-time-wrapper">
          
          <time>2026-01-17</time>
          
            
              <span class="post-category"><a href="/categories/Academic/">Academic</a></span>
            
          
        </div>
      </div>
      <h1 class="post-title syuanpi fadeInRightShort back-2">
        
          <a href="/2026/01/17/FlashAttention/">FlashAttention</a>
        
      </h1>
    </header>
    <div class="post-content syuanpi fadeInRightShort back-3">
      
        
          <p>FlashAttention的目的很简单：<br>
如何高效计算<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="23.85ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 10541.9 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path></g><g data-mml-node="mo" transform="translate(1040.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2096.6,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(2846.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3207.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3568.6,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4034.6,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4634.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4995.6,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5340.6,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(5825.6,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(6425.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6814.6,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mo" transform="translate(7605.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8050.2,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mo" transform="translate(8939.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(9383.9,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g><g data-mml-node="mo" transform="translate(10152.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p>
<h3 id="FlashAttention-1实现">FlashAttention-1实现</h3>
<img src="/2026/01/17/FlashAttention/image.png" class="" title="This is an example image">
<ul>
<li><strong>分块计算<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="5.233ex" height="2.343ex" role="img" focusable="false" viewBox="0 -841.7 2312.8 1035.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="msup" transform="translate(791,0)"><g data-mml-node="mi"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(974,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></g></svg></mjx-container>但不存储它</strong><br>
从上方图可以看出，原始的FA设计是outer loop为KV blocks，inner loop为Q<br>
可以在不同batch与不同head上并行，单个batch上单个head的双重循环是串行的</li>
<li><strong>O的合并更新</strong><br>
第<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container>行：维护$lse_i=log\sum_j exp((Q_iK_j^T)<em>{ij})<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 1000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">与</text></g></g></g></svg></mjx-container>m_i=max((Q_iK_j^T)</em>{ij})<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 1000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g></g></g></svg></mjx-container>o_i=\sum_j exp((QK^T)_{ij}-m_i)V_j<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="22.624ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 10000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">这</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">样</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">可</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">以</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">实</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">现</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">在</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">线</text></g><g data-mml-node="mi" transform="translate(8000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">更</text></g><g data-mml-node="mi" transform="translate(9000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">新</text></g></g></g></svg></mjx-container>o_i$，具体实现见代码</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.14135">FA arxiv link</a><br>
<a target="_blank" rel="noopener" href="https://github.com/Dao-AILab/flash-attention">github link</a></p>
<h3 id="NSA的GQA版本FA的实现">NSA的GQA版本FA的实现</h3>
<h4 id="修改双重循环">修改双重循环</h4>
<p>DeepSeekNSA中的Triton实现的FlashAttention Forward Kernel<br>
外层循环q block(其实是并行的)，内层循环kv block(在线程块内串行)<br>
FlashAttenion-2中其实也做了一样的修改，这样q block也可以并行，而如果按照原来的做法，q block是无法并行的，因为会涉及到o的更新的数据同步问题</p>
<h4 id="代码分析">代码分析</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_kernel</span>(<span class="params"></span></span><br><span class="line"><span class="params">    q_ptr,  <span class="comment"># Q: n x NUM_Q_HEADS(h) x qk_head_dim(d) 这里n都是整个序列长(所有batch拼成的)</span></span></span><br><span class="line"><span class="params">    k_ptr,  <span class="comment"># K: n x NUM_KV_HEADS(h) x qk_head_dim(d)</span></span></span><br><span class="line"><span class="params">    v_ptr,  <span class="comment"># V: n x NUM_KV_HEADS(h) x v_head_dim(d)</span></span></span><br><span class="line"><span class="params">    o_ptr,  <span class="comment"># O: n x NUM_Q_HEADS(h) x v_head_dim(d)</span></span></span><br><span class="line"><span class="params">    lse_ptr,  <span class="comment"># LSE: NUM_Q_HEADS(h) x n   (log-sum-exp)</span></span></span><br><span class="line"><span class="params">    <span class="comment"># seqlens</span></span></span><br><span class="line"><span class="params">    cu_seqlens_q, <span class="comment"># 累积序列长度，用于处理可变长度序列，描述长度为n的完整序列中每个batch的范围</span></span></span><br><span class="line"><span class="params">    <span class="comment"># 存储：[0, seq_len1, seq_len1+seq_len2, ...] [0,seq_len1)为batch0，[seq_len1,seq_len2)为batch1，...</span></span></span><br><span class="line"><span class="params">    cu_seqlens_k, <span class="comment"># 用于处理cross-attention的情况，但在self attention中与cu_seqlens_q应当一致</span></span></span><br><span class="line"><span class="params">    <span class="comment"># shape</span></span></span><br><span class="line"><span class="params">    NUM_KV_HEADS, <span class="comment"># Key/Value的头数</span></span></span><br><span class="line"><span class="params">    NUM_SHARE_Q_HEADS, <span class="comment"># 共享一个Key/Value头的Query头数，即一个查询组中的查询头数G</span></span></span><br><span class="line"><span class="params">    qk_head_dim, <span class="comment"># query与key向量的维数 d</span></span></span><br><span class="line"><span class="params">    v_head_dim,  <span class="comment"># value与output向量的维数 d 二者一般一样</span></span></span><br><span class="line"><span class="params">    <span class="comment"># sm_scale</span></span></span><br><span class="line"><span class="params">    sm_scale, <span class="comment"># softmax计算前的缩放因子，保证注意力分数分布的标准差大致为1，取1/sqrt(qk_head_dim)</span></span></span><br><span class="line"><span class="params">    <span class="comment"># causal</span></span></span><br><span class="line"><span class="params">    causal, <span class="comment"># 是否使用因果掩码</span></span></span><br><span class="line"><span class="params">    <span class="comment"># gqa</span></span></span><br><span class="line"><span class="params">    gqa_interleave,</span></span><br><span class="line"><span class="params">    <span class="comment"># stride 四个矩阵的物理stride</span></span></span><br><span class="line"><span class="params">    stride_qn,</span></span><br><span class="line"><span class="params">    stride_qh,</span></span><br><span class="line"><span class="params">    stride_qd,</span></span><br><span class="line"><span class="params">    stride_kn,</span></span><br><span class="line"><span class="params">    stride_kh,</span></span><br><span class="line"><span class="params">    stride_kd,</span></span><br><span class="line"><span class="params">    stride_vn,</span></span><br><span class="line"><span class="params">    stride_vh,</span></span><br><span class="line"><span class="params">    stride_vd,</span></span><br><span class="line"><span class="params">    stride_on,</span></span><br><span class="line"><span class="params">    stride_oh,</span></span><br><span class="line"><span class="params">    stride_od,</span></span><br><span class="line"><span class="params">    stride_lh,</span></span><br><span class="line"><span class="params">    stride_ln,</span></span><br><span class="line"><span class="params">    <span class="comment"># META parameters</span></span></span><br><span class="line"><span class="params">    BLOCK_SIZE_Q: tl.constexpr,  <span class="comment"># q block size </span></span></span><br><span class="line"><span class="params">    BLOCK_SIZE_K: tl.constexpr,  <span class="comment"># k block size FlashAttention内层循环的步长/块大小</span></span></span><br><span class="line"><span class="params">    BLOCK_SIZE_KD: tl.constexpr, <span class="comment"># 大于等于qk_head_dim的2的幂，用于加载</span></span></span><br><span class="line"><span class="params">    BLOCK_SIZE_VD: tl.constexpr, <span class="comment"># 大于等于v_head_dim的2的幂，用于加载</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    qk_scale = sm_scale * <span class="number">1.44269504</span> <span class="comment"># 输入的sm_scale是按照softmax使用e^x计算，但实际使用的函数是2^x，这里是乘以1/ln2来补偿</span></span><br><span class="line">    <span class="comment"># get batch id and head id</span></span><br><span class="line">    pid_b = tl.program_id(<span class="number">0</span>) <span class="comment"># 批次（batch）的索引(多个batch序列被拼成一个很长的token序列)</span></span><br><span class="line">    pid_h = tl.program_id(<span class="number">1</span>) <span class="comment"># query头（head）的索引</span></span><br><span class="line">    pid_q = tl.program_id(<span class="number">2</span>) <span class="comment"># 这一query头的在其所在的batch序列内的块索引</span></span><br><span class="line">    <span class="keyword">if</span> gqa_interleave:</span><br><span class="line">        pid_kh = pid_h % NUM_KV_HEADS <span class="comment"># kv头的索引 GQA中同查询组query头共用kv头</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pid_kh = pid_h // NUM_SHARE_Q_HEADS</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># get q k start and len after rmpad 根据pid_b确定batch序列的范围，该线程块只处理这个batch中的一个BLOCK_SIZE_Q大小的块</span></span><br><span class="line">    q_start = tl.load(cu_seqlens_q + pid_b)</span><br><span class="line">    q_len = tl.load(cu_seqlens_q + pid_b + <span class="number">1</span>) - q_start <span class="comment"># 这个batch处理的是[q_start,q_start+q_len)的输入序列</span></span><br><span class="line">    k_start = tl.load(cu_seqlens_k + pid_b)</span><br><span class="line">    k_len = tl.load(cu_seqlens_k + pid_b + <span class="number">1</span>) - k_start</span><br><span class="line">    <span class="keyword">if</span> BLOCK_SIZE_Q * pid_q &gt;= q_len: </span><br><span class="line">        <span class="comment"># 如果当前q_block块索引范围[BLOCK_SIZE_Q * pid_q, BLOCK_SIZE_Q * (pid_q+1))完全超过了当前batch范围，直接返回</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># init qkv pointer</span></span><br><span class="line">    q_ptrs = tl.make_block_ptr(</span><br><span class="line">        base=q_ptr + q_start * stride_qn + pid_h * stride_qh,</span><br><span class="line">        shape=(q_len, qk_head_dim),</span><br><span class="line">        strides=(stride_qn, stride_qd),</span><br><span class="line">        offsets=(pid_q * BLOCK_SIZE_Q, <span class="number">0</span>),</span><br><span class="line">        block_shape=(BLOCK_SIZE_Q, BLOCK_SIZE_KD),</span><br><span class="line">        order=(<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    )</span><br><span class="line">    k_ptrs = tl.make_block_ptr(</span><br><span class="line">        base=k_ptr + k_start * stride_kn + pid_kh * stride_kh,</span><br><span class="line">        shape=(qk_head_dim, k_len),</span><br><span class="line">        strides=(stride_kd, stride_kn),</span><br><span class="line">        offsets=(<span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">        block_shape=(BLOCK_SIZE_KD, BLOCK_SIZE_K),</span><br><span class="line">        order=(<span class="number">0</span>, <span class="number">1</span>), <span class="comment"># 这里的block ptr在初始化的时候就是转置的</span></span><br><span class="line">    )</span><br><span class="line">    v_ptrs = tl.make_block_ptr(</span><br><span class="line">        base=v_ptr + k_start * stride_vn + pid_kh * stride_vh,</span><br><span class="line">        shape=(k_len, v_head_dim),</span><br><span class="line">        strides=(stride_vn, stride_vd),</span><br><span class="line">        offsets=(<span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">        block_shape=(BLOCK_SIZE_K, BLOCK_SIZE_VD),</span><br><span class="line">        order=(<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># load q 本线程块只需加载一次即可</span></span><br><span class="line">    q = tl.load(q_ptrs, boundary_check=(<span class="number">0</span>, <span class="number">1</span>), padding_option=<span class="string">"zero"</span>)</span><br><span class="line">    <span class="comment"># init statistics</span></span><br><span class="line">    off_q = tl.arange(<span class="number">0</span>, BLOCK_SIZE_Q) + pid_q * BLOCK_SIZE_Q</span><br><span class="line">    off_k = tl.arange(<span class="number">0</span>, BLOCK_SIZE_K)</span><br><span class="line">    m_i = tl.full((BLOCK_SIZE_Q,), <span class="built_in">float</span>(<span class="string">"-inf"</span>), dtype=tl.float32) <span class="comment"># 各行最大的e^qk</span></span><br><span class="line">    lse_i = tl.full((BLOCK_SIZE_Q,), <span class="built_in">float</span>(<span class="string">"-inf"</span>), dtype=tl.float32) <span class="comment"># 各行qk的lse logΣe^qk</span></span><br><span class="line">    acc_o = tl.full((BLOCK_SIZE_Q, BLOCK_SIZE_VD), <span class="number">0</span>, dtype=tl.float32) <span class="comment"># 最终结果O 在循环过程中存放的qk*v再除以exp2(m_i)的中间结果</span></span><br><span class="line">    <span class="comment"># full attention or causal attention</span></span><br><span class="line">    lo = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> causal:</span><br><span class="line">        hi = <span class="built_in">min</span>(k_len, (pid_q + <span class="number">1</span>) * BLOCK_SIZE_Q)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        hi = k_len</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lo, hi, BLOCK_SIZE_K):</span><br><span class="line">        i = tl.multiple_of(i, BLOCK_SIZE_K)</span><br><span class="line">        <span class="comment"># load k^T</span></span><br><span class="line">        k = tl.load(k_ptrs, boundary_check=(<span class="number">1</span>, <span class="number">0</span>), padding_option=<span class="string">"zero"</span>)</span><br><span class="line">        <span class="comment"># compute qk^T</span></span><br><span class="line">        qk = tl.zeros((BLOCK_SIZE_Q, BLOCK_SIZE_K), dtype=tl.float32)</span><br><span class="line">        <span class="keyword">if</span> causal:</span><br><span class="line">            qk += tl.where(off_q[:, <span class="literal">None</span>] &gt;= (i + off_k)[<span class="literal">None</span>, :], <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">"-inf"</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            qk += tl.where((off_k &lt; k_len - i)[<span class="literal">None</span>, :], <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">"-inf"</span>))</span><br><span class="line">        qk += tl.dot(q, k) * qk_scale</span><br><span class="line">        <span class="comment"># compute m_ij and l_ij</span></span><br><span class="line">        m_ij = tl.maximum(m_i, tl.<span class="built_in">max</span>(qk, axis=<span class="number">1</span>)) <span class="comment"># 大小：BLOCK_SIZE_Q，每行求最大值</span></span><br><span class="line">        p = tl.math.exp2(qk - m_ij[:, <span class="literal">None</span>]) <span class="comment"># 本块放缩后的注意力分数，BLOCK_SIZE_Q * BLOCK_SIZE_K</span></span><br><span class="line">        l_ij = tl.<span class="built_in">sum</span>(p, axis=<span class="number">1</span>) <span class="comment"># 本块放缩后的注意力分数和se，BLOCK_SIZE_Q</span></span><br><span class="line">        <span class="comment"># scale acc_o</span></span><br><span class="line">        acc_o_scale = tl.math.exp2(m_i - m_ij)</span><br><span class="line">        acc_o = acc_o * acc_o_scale[:, <span class="literal">None</span>] <span class="comment"># 将放缩量更新为exp2(m_ij)</span></span><br><span class="line">        <span class="comment"># load v and update acc_o</span></span><br><span class="line">        v = tl.load(v_ptrs, boundary_check=(<span class="number">0</span>, <span class="number">1</span>), padding_option=<span class="string">"zero"</span>) <span class="comment"># BLOCK_K * v_head_dim</span></span><br><span class="line">        p = p.to(v.dtype)</span><br><span class="line">        acc_o += tl.dot(p, v)</span><br><span class="line">        <span class="comment"># update statistics</span></span><br><span class="line">        m_i = m_ij</span><br><span class="line">        lse_i = m_ij + tl.math.log2(tl.math.exp2(lse_i - m_ij) + l_ij)</span><br><span class="line">        <span class="comment"># update ptrs</span></span><br><span class="line">        k_ptrs = tl.advance(k_ptrs, (<span class="number">0</span>, BLOCK_SIZE_K)) <span class="comment"># FlashAttention内层循环移动</span></span><br><span class="line">        v_ptrs = tl.advance(v_ptrs, (BLOCK_SIZE_K, <span class="number">0</span>))</span><br><span class="line">    <span class="comment"># final scale</span></span><br><span class="line">    acc_o = acc_o * tl.math.exp2(m_i - lse_i)[:, <span class="literal">None</span>]</span><br><span class="line">    <span class="comment"># save output</span></span><br><span class="line">    o_ptrs = tl.make_block_ptr(</span><br><span class="line">        base=o_ptr + q_start * stride_on + pid_h * stride_oh,</span><br><span class="line">        shape=(q_len, v_head_dim),</span><br><span class="line">        strides=(stride_on, stride_od),</span><br><span class="line">        offsets=(pid_q * BLOCK_SIZE_Q, <span class="number">0</span>),</span><br><span class="line">        block_shape=(BLOCK_SIZE_Q, BLOCK_SIZE_VD),</span><br><span class="line">        order=(<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    )</span><br><span class="line">    tl.store(o_ptrs, acc_o.to(o_ptr.dtype.element_ty), boundary_check=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># save lse</span></span><br><span class="line">    l_ptrs = lse_ptr + q_start * stride_ln + pid_h * stride_lh + off_q * stride_ln</span><br><span class="line">    tl.store(l_ptrs, lse_i, mask=off_q &lt; q_len)</span><br></pre></td></tr></table></figure>
        
      
    
    </div>
    
      <div class="post-tags syuanpi fadeInRightShort back-3">
      
        <a href="/tags/Literature-Review/">Literature Review</a>
      
      </div>
    
    
  </article>
  
  
    
  

  
    
  
  <article class="
  post
  
  ">
    <header class="post-header">
      <div class="post-time syuanpi fadeInRightShort back-1">
        <div class="post-time-wrapper">
          
          <time>2026-01-16</time>
          
            
              <span class="post-category"><a href="/categories/Life/">Life</a></span>
            
          
        </div>
      </div>
      <h1 class="post-title syuanpi fadeInRightShort back-2">
        
          <a href="/2026/01/16/hello-world/">CQ CQ This is BD1AEH. Standing by.</a>
        
      </h1>
    </header>
    <div class="post-content syuanpi fadeInRightShort back-3">
      
        
          <p><a target="_blank" rel="noopener" href="https://www.qrz.com/db/BD1AEH">QRZ link</a></p>
<p>开通了hexo，把blog部署在了<a target="_blank" rel="noopener" href="https://github.com/hanjc24/hanjc24.github.io">git</a>上</p>
<p>hexo配置参考: <a target="_blank" rel="noopener" href="https://xuxu20040407.github.io/2024/09/15/hexo/hexo/">this</a> and <a target="_blank" rel="noopener" href="https://aajax.top/">this</a></p>

        
      
    
    </div>
    
      <div class="post-tags syuanpi fadeInRightShort back-3">
      
        <a href="/tags/Daily-Log/">Daily Log</a>
      
      </div>
    
    
  </article>
  
  
    
  

  
</section>

  
  <nav class="pagination">
      <a class="extend prev" rel="prev" href="/"><i class="iconfont icon-doubleleft"></i>Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>



        </div>
      </main>
      <footer class="footer syuanpi fadeIn" id="footer">
  <hr>
  <div class="footer-wrapper">
    <div class="left">
      <div class="contact-icon">
  
  
    <a target="_blank" rel="noopener" href="https://github.com/hanjc24" class="iconfont icon-github" title="github"></a>
  
</div>

    </div>
    <div class="right">
      <div class="copyright">
    <div class="info">
        <span>&copy;</span>
        <span>2026 ~ 2026</span>
        <span>❤</span>
        <span>hanjc24</span>
    </div>
    <div class="theme">
        <span>
            Powered by
            <a href="http://hexo.io/" target="_blank" rel="noopener">Hexo </a>
        </span>
        <span>
            Theme
            <a target="_blank" rel="noopener" href="https://github.com/ColMugX/hexo-theme-Nlvi"> Nlvi </a>
        </span>
    </div>
    
</div>

    </div>
  </div>
</footer>
    </div>
    <div class="tagcloud" id="tagcloud">
  <div class="tagcloud-taglist">
  
    <div class="tagcloud-tag">
      <button>Daily Log</button>
    </div>
  
    <div class="tagcloud-tag">
      <button>Literature Review</button>
    </div>
  
    <div class="tagcloud-tag">
      <button>Tutorial</button>
    </div>
  
    <div class="tagcloud-tag">
      <button>Project</button>
    </div>
  
    <div class="tagcloud-tag">
      <button>李宏毅ML</button>
    </div>
  
  </div>
  
    <div class="tagcloud-postlist active">
      <h2>Daily Log</h2>
      
        <div class="tagcloud-post">
          <a href="/2026/01/16/hello-world/">
            <time class="tagcloud-posttime">2026 / 01 / 16</time>
            <span>CQ CQ This is BD1AEH. Standing by.</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/19/CQ-CQ-CQ-This-is-BD1AEH-calling/">
            <time class="tagcloud-posttime">2026 / 01 / 19</time>
            <span>CQ CQ CQ This is BD1AEH calling</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/20/EETalk-Project/">
            <time class="tagcloud-posttime">2026 / 01 / 20</time>
            <span>EETalk Project</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/THUCS培养体系/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>THU-CS培养方案</span>
          </a>
        </div>
      
    </div>
  
    <div class="tagcloud-postlist ">
      <h2>Literature Review</h2>
      
        <div class="tagcloud-post">
          <a href="/2026/01/17/FlashAttention/">
            <time class="tagcloud-posttime">2026 / 01 / 17</time>
            <span>FlashAttention</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/18/infllmv2-paper-review/">
            <time class="tagcloud-posttime">2026 / 01 / 18</time>
            <span>Infllmv2 Review</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/19/DeepSeekNSA/">
            <time class="tagcloud-posttime">2026 / 01 / 19</time>
            <span>DeepSeekNSA</span>
          </a>
        </div>
      
    </div>
  
    <div class="tagcloud-postlist ">
      <h2>Tutorial</h2>
      
        <div class="tagcloud-post">
          <a href="/2026/01/17/HexoNlviBuild/">
            <time class="tagcloud-posttime">2026 / 01 / 17</time>
            <span>How to customize Hexo theme Nlvi</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/18/How-to-use-Mermaid-in-Hexo/">
            <time class="tagcloud-posttime">2026 / 01 / 18</time>
            <span>How to use Mermaid in Hexo</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/22/Learning-Triton/">
            <time class="tagcloud-posttime">2026 / 01 / 22</time>
            <span>Learning Triton</span>
          </a>
        </div>
      
    </div>
  
    <div class="tagcloud-postlist ">
      <h2>Project</h2>
      
        <div class="tagcloud-post">
          <a href="/2026/01/20/EETalk-Project/">
            <time class="tagcloud-posttime">2026 / 01 / 20</time>
            <span>EETalk Project</span>
          </a>
        </div>
      
    </div>
  
    <div class="tagcloud-postlist ">
      <h2>李宏毅ML</h2>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L1Regression/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L1 Regression</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L2TrainIssue/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L2 Train Issue</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L3Classification/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L3 Classification</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L5SelfAttention/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L5 Self-Attention</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L6Transformer/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L6 Transformer</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L8self-supervised/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L8 Self-supervised Learning</span>
          </a>
        </div>
      
        <div class="tagcloud-post">
          <a href="/2026/01/24/L4CNN/">
            <time class="tagcloud-posttime">2026 / 01 / 24</time>
            <span>LHY-L4 CNN</span>
          </a>
        </div>
      
    </div>
  
</div>

  </div>
  <div class="backtop syuanpi melt toTop" id="backtop">
    <i class="iconfont icon-up"></i>
    <span style="text-align:center;font-family:Georgia;"><span style="font-family:Georgia;" id="scrollpercent">1</span>%</span>
</div>

  <div class="search" id="search">
    <div class="input">
      <input type="text" id="search-input" placeholder="搜索一下？" autofocus>
    </div>
    <div id="search-result"></div>
  </div>



<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>








  <script></script>
  <script src="/script/lib/lightbox/js/lightbox.min.js" async></script>





  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>







  
<script src="/script/scheme/banderole.js"></script>




<script src="/script/bootstarp.js"></script>





  
<script src="/script/lib/mermaid/mermaid.min.js"></script>

  <script>
    $(document).ready(function() {
      var mermaid_config = {
        startOnLoad: true,
        theme: '',
        flowchart: {
          useMaxWidth: false,
          htmlLabels: true
        }
      };
      mermaid.initialize(mermaid_config);
    });
  </script>


</body>
</html>
